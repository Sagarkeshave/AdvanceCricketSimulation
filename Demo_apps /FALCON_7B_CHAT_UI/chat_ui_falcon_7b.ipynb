{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyN4z1sLWlX27Zusgl9zI7CC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagarkeshave/AdvanceCricketSimulation/blob/main/Demo_apps%20/FALCON_7B_CHAT_UI/chat_ui_falcon_7b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSJRYCGDujDA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langchain huggingface_hub watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%load_ext watermark\n",
        "%watermark -a \"Sagar Keshave\" -vmp langchain,huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX5YCiODu5M1",
        "outputId": "b74dba3d-5ab2-4eb7-c086-f2c224599ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Sagar Keshave\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "langchain      : 0.0.284\n",
            "huggingface_hub: 0.16.4\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.109+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get your Huggingface access token from https://huggingface.co/settings/tokens \n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "HUGGINGFACE_API_TOKEN = getpass()\n",
        "os.environ[\"HUGGINGFACE_API_TOKEN\"] = HUGGINGFACE_API_TOKEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzxxOxaxvWRB",
        "outputId": "b690fe53-493a-4dbb-d1dd-e96a082c16e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We are using FALCON-7B-INSTRUCT model [Huggingface website](https://huggingface.co/tiiuae/falcon-7b-instruct)"
      ],
      "metadata": {
        "id": "aPYxM1FPxgN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token=HUGGINGFACE_API_TOKEN,\n",
        "                     repo_id=repo_id,\n",
        "                     model_kwargs={\"temperature\":0.7, \"max_new_tokens\":700})"
      ],
      "metadata": {
        "id": "FUB7HY4MxQnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"\n",
        "You are a helpful AI assistant and provide the answer for the question asked politely.\n",
        "\n",
        "{question}\n",
        "Answer: Let's think step by step.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"How to cook Pizza ?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ],
      "metadata": {
        "id": "Dsbp5EnLyN2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a15eb9a-ab78-44b8-d08f-6b37c86ef33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Preheat the oven at the desired temperature.\n",
            "2. Roll out the pizza dough on a baking sheet or pizza stone.\n",
            "3. Spread the pizza dough with tomato sauce.\n",
            "4. Add the desired amount of cheese and toppings.\n",
            "5. Place the pizza in the preheated oven.\n",
            "6. Bake the pizza for the desired time.\n",
            "7. Let the pizza cool for a few minutes before slicing.\n",
            "8. Enjoy your homemade pizza!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soCGfEZatUDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}